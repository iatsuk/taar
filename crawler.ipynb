{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipes crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ru_RU.UTF-8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from lxml import html, etree\n",
    "from datetime import datetime\n",
    "import unicodedata\n",
    "import locale\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'ru_RU.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseScrapper:\n",
    "\n",
    "    def __init__(self, url: str, user_agent: str = UserAgent().random):\n",
    "        self._url: str = url\n",
    "        self._data_to_return: list = None\n",
    "        self._current_pos: int = -1\n",
    "        self._session = requests.Session()\n",
    "        self._session.headers.update({'User-Agent': user_agent,})\n",
    "\n",
    "    def __iter__(self) -> iter:\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._data_to_return is None:\n",
    "            self._data_to_return = self._fetch_data()\n",
    "        self._current_pos += 1\n",
    "        if self._current_pos >= len(self._data_to_return):\n",
    "            raise StopIteration\n",
    "        return self._data_to_return[self._current_pos]\n",
    "        \n",
    "    def _fetch_data(self) -> set:\n",
    "        page = self._get_page(self._url)\n",
    "        data = self._extract_data(page)\n",
    "        return data\n",
    "\n",
    "    def _get_page(self, url) -> html.HtmlElement:\n",
    "        content = self._session.get(url).text\n",
    "        if (self._session.status_code != requests.codes.ok):\n",
    "            raise Exception('Response code', self._session.status_code, 'for url', url)\n",
    "        parsed = html.fromstring(content)\n",
    "        return parsed\n",
    "\n",
    "    def _extract_data(self, parsed: html.HtmlElement) -> list:\n",
    "        result = []\n",
    "        articles = self._get_articles(parsed)\n",
    "        for article in articles:\n",
    "            try:\n",
    "                result.append(self._extract_data_elem(article))\n",
    "            except Exception as e:\n",
    "                print('Article:', etree.tostring(article))\n",
    "                raise e\n",
    "        return result\n",
    "    \n",
    "    def _get_articles(self, parsed: html.HtmlElement) -> list:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _extract_data_elem(self, article: html.HtmlElement) -> dict:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return '{clazz}({sep}host={host},{sep}fetched={fetched},\\n)'.format(\n",
    "            sep='\\n\\t',\n",
    "            clazz=self.__class__.__name__,\n",
    "            host=self._host,\n",
    "            fetched=(self._data_to_return is not None),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MailRuScrapper(BaseScrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(host='https://news.mail.ru')\n",
    "        \n",
    "    def _next_page_url(self, parsed: html.HtmlElement) -> str:\n",
    "        pass\n",
    "\n",
    "    def _get_articles(self, parsed: html.HtmlElement) -> list:\n",
    "        return parsed.xpath('//div[contains(@class,\"newsitem_height\")]')\n",
    "\n",
    "    def _extract_data_elem(self, article: html.HtmlElement) -> dict:\n",
    "        return {\n",
    "            'raw': etree.tostring(article),\n",
    "            'url': self._host + article.xpath('.//span[@class=\"cell\"]/a[@class=\"newsitem__title link-holder\"]/@href')[0], \n",
    "            'header': unicodedata.normalize('NFKD', article.xpath('.//span[@class=\"newsitem__title-inner\"]/text()')[0]),\n",
    "            'date': datetime.strptime(article.xpath('.//div[@class=\"newsitem__params\"]/span[contains(@class,\"js-ago\")]/@datetime')[0], '%Y-%m-%dT%H:%M:%S%z'),\n",
    "            'source': unicodedata.normalize('NFKD', article.xpath('.//div[@class=\"newsitem__params\"]/span[@class=\"newsitem__param\"]/text()')[0]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persisting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mongodb docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a30840108e9e6d7f28141e005ef0024c6b8d01b52b7cd03c7bc88e7ab564c2b2\n"
     ]
    }
   ],
   "source": [
    "!docker run -d -p 27017:27017 --name mongodb mongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start mongo db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker start mongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run spiders and fill database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo = MongoClient('localhost', 27017)\n",
    "db = mongo['food_db']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_via_scrapper(recipes, collection):\n",
    "    for recipe in recipes:\n",
    "        if collection.update_one({'_id': recipe['url']}, {'$set': recipe}, upsert=True).matched_count != 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dump from mongodb container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec -it mongodb mongodump --out=/backup/ --db=food_db --collection=recipes \n",
    "!docker exec -it mongodb tar czf dump.mongo.tgz /backup\n",
    "!docker cp mongodb:/dump.mongo.tgz dump.mongo.tgz\n",
    "!docker exec -it mongodb rm -rf /backup /dump.mongo.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put dump into mongodb container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker cp dump.mongo.tgz mongodb:/dump.mongo.tgz\n",
    "!docker exec -it mongodb tar xzf dump.mongo.tgz\n",
    "!docker exec -it mongodb mongorestore /backup\n",
    "!docker exec -it mongodb rm -rf /backup /dump.mongo.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shutdown mongo db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker stop mongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ingr, collection, limit):\n",
    "    for recipe in collection.find({'ingr': ingr}, {'name': 1, 'ingr': 1, 'url': 1}):\n",
    "        print(recipe['name'])\n",
    "        print('url:', recipe['url'])\n",
    "        pprint(recipe['ingr'])\n",
    "        print()\n",
    "        limit -= 1\n",
    "        if limit <= 0:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data('фарш', food_db.recipes, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
